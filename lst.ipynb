{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import librosa\n",
    "import google.generativeai as genai\n",
    "import yaml\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.3862776e-02, -1.7331528e-02, -1.6357925e-02, ...,\n",
       "        9.8206228e-06, -1.7608858e-07,  9.6336289e-06], dtype=float32)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "og_arr, og_sr = librosa.load(\"data/music.mp3\")\n",
    "og_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_arr = librosa.stft(og_arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### zero shot audio detection\n",
    "* [clap model](https://huggingface.co/docs/transformers/model_doc/clap): it requires a text input which it yields a probability for. Perhaps get the set of species based on location and then use the model to tell us which one it could be? But the training set would require to have the insect sounds. Dataset of insect noises then to train on/\n",
    "* just into a multimodal llm?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"config.yaml\", \"r\") as conf_file:\n",
    "    config = yaml.safe_load(conf_file)\n",
    "genai.configure(api_key=config[\"GEMINI_KEY\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upload_to_gemini(path, mime_type=None):\n",
    "  \"\"\"Uploads the given file to Gemini.\n",
    "\n",
    "  See https://ai.google.dev/gemini-api/docs/prompting_with_media\n",
    "  \"\"\"\n",
    "  file = genai.upload_file(path, mime_type=mime_type)\n",
    "  print(f\"Uploaded file '{file.display_name}' as: {file.uri}\")\n",
    "  return file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded file 'music.mp3' as: https://generativelanguage.googleapis.com/v1beta/files/r3mk9g51uz0h\n"
     ]
    }
   ],
   "source": [
    "audio_file = upload_to_gemini(\"data/music.mp3\", mime_type=\"audio/x-mp3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unfortunately, I cannot listen to and process audio information like identifying the drum pattern from a song. If you could provide a description of the drum pattern like kick on 1 & 3, snare on 2 & 4, that would be helpful. \n",
      "\n",
      "However, I can give you some general tips on recreating drum patterns in a sequencer:\n",
      "\n",
      "1. **Identify the tempo:** Most sequencers allow you to set a specific tempo (BPM) which is crucial for accurate recreation.\n",
      "2. **Break down the pattern:** Listen carefully for kick, snare, hi-hat, and any other percussive elements. Focus on identifying where they land within each measure. \n",
      "3. **Start with the basics:** Begin by laying down the kick and snare pattern as they form the foundation of most drum grooves. \n",
      "4. **Layer the hi-hats:** Experiment with different hi-hat patterns to add groove and complexity.\n",
      "5. **Fine-tune and add variation:** Don't be afraid to adjust the velocity and timing of individual hits to create a more human feel.\n",
      "\n",
      "Let me know if you have any more questions about music production or using a sequencer. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = genai.GenerativeModel(model_name=\"models/gemini-1.5-pro-latest\")\n",
    "prompt = \"give me the exact drum pattern in this song so I can recreate it in a sequencer\"\n",
    "response = model.generate_content([prompt, audio_file])\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "exp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

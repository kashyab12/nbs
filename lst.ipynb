{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import librosa\n",
    "import google.generativeai as genai\n",
    "import yaml\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_209950/3759619369.py:1: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  og_arr, og_sr = librosa.load(\"data/backyard-specs.m4a\")\n",
      "/home/kashyab/.pyenv/versions/3.11.8/envs/exp/lib/python3.11/site-packages/librosa/core/audio.py:184: FutureWarning: librosa.core.audio.__audioread_load\n",
      "\tDeprecated as of librosa version 0.10.0.\n",
      "\tIt will be removed in librosa version 1.0.\n",
      "  y, sr_native = __audioread_load(path, offset, duration, dtype)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00, ...,\n",
       "       -3.4807206e-05,  2.6605767e-04,  3.1566259e-04], dtype=float32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "og_arr, og_sr = librosa.load(\"data/backyard-specs.m4a\")\n",
    "og_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_arr = librosa.stft(og_arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### zero shot audio detection\n",
    "* [clap model](https://huggingface.co/docs/transformers/model_doc/clap): it requires a text input which it yields a probability for. Perhaps get the set of species based on location and then use the model to tell us which one it could be? But the training set would require to have the insect sounds. Dataset of insect noises then to train on/\n",
    "* just into a multimodal llm?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"config.yaml\", \"r\") as conf_file:\n",
    "    config = yaml.safe_load(conf_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading file...\n",
      "Completed upload: https://generativelanguage.googleapis.com/v1beta/files/ixswtxq7yrvz\n"
     ]
    }
   ],
   "source": [
    "print(f\"Uploading file...\")\n",
    "audio_file = genai.upload_file(path=\"data/backyard-specs.m4a\")\n",
    "print(f\"Completed upload: {audio_file.uri}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video processing complete: https://generativelanguage.googleapis.com/v1beta/files/ixswtxq7yrvz\n"
     ]
    }
   ],
   "source": [
    "while audio_file.state.name == \"PROCESSING\":\n",
    "    print('Waiting for audio to be processed.')\n",
    "    time.sleep(10)\n",
    "    audio_file = genai.get_file(audio_file.name)\n",
    "\n",
    "if audio_file.state.name == \"FAILED\":\n",
    "  raise ValueError(audio_file.state.name)\n",
    "print(f'Video processing complete: ' + audio_file.uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I can't hear any insects in this audio recording. It sounds like background noise, perhaps of traffic or some machinery. \n"
     ]
    }
   ],
   "source": [
    "genai.configure(api_key=config[\"GEMINI_KEY\"])\n",
    "model = genai.GenerativeModel(model_name=\"gemini-1.5-flash-latest\")\n",
    "prompt = \"What kinds of insects do you hear in this audio recording? I live in San Jose, California so that may help you make a better decision\"\n",
    "response = model.generate_content([prompt, audio_file])\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "exp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
